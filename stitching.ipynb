{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# За порамнување на figures\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# Големина на figure за да се доволно големи сликите\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addImages(img1, img2):\n",
    "    if(img1.shape[1] > img2.shape[1]):\n",
    "        print(\"ERROR\")\n",
    "        \n",
    "    result = []\n",
    "    for y in range(img1.shape[0]):\n",
    "        result.append([])\n",
    "        for x in range(img1.shape[1]):            \n",
    "            z = img1[y, x, 3]\n",
    "            if(z <= 10):\n",
    "                result[y].append(img2[y, x])\n",
    "            else:\n",
    "                result[y].append(img1[y, x])\n",
    "        \n",
    "        for x in range(img1.shape[1], img2.shape[1]):\n",
    "            result[y].append(img2[y, x])\n",
    "    \n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функција која спојува 2 слики во панорама, ако имаат доволно слични карактеристики\n",
    "def stitch(img1, img2, detectortype, matchertype, percentagematches, crop = False):\n",
    "    \n",
    "    # За наоѓање на дескрипторите и клучните точки, подобро е процесирање\n",
    "    # врз монохроматска / црно-бела слика, затоа ги конвертираме сликите.\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGRA2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "    # Приказ на 2те слики\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, constrained_layout=False, figsize=(16, 9))\n",
    "    ax1.set_xlabel(\"Слика 1\", fontsize=14)\n",
    "    ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGRA2RGB))\n",
    "    ax2.set_xlabel(\"Слика 2\", fontsize=14)\n",
    "    ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGRA2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    descriptorDetector = None\n",
    "    k1 = None\n",
    "    k2 = None\n",
    "    d1 = None\n",
    "    d2 = None\n",
    "    \n",
    "    # Детекција на дескрипторите и клучните точки на дадените црно-бели слики,\n",
    "    # со користење на еден од постоечките алгоритми како SIFT, SURT, ORB, etc.\n",
    "    if detectortype == \"SIFT\":\n",
    "        descriptorDetector = cv2.SIFT_create()\n",
    "        k1, d1 = descriptorDetector.detectAndCompute(img1_gray, None)\n",
    "        k2, d2 = descriptorDetector.detectAndCompute(img2_gray, None)\n",
    "    elif detectortype == \"ORB\":\n",
    "        descriptorDetector = cv2.ORB_create()\n",
    "        k1, d1 = descriptorDetector.detectAndCompute(img1_gray, None)\n",
    "        k2, d2 = descriptorDetector.detectAndCompute(img2_gray, None)\n",
    "\n",
    "    matcher = None\n",
    "    \n",
    "    # Matcher кој (зависно од методот), за дадени 2 листи на дескриптори, ги\n",
    "    # наоѓа паровите дескриптори од 2те слики кои се доволно слични / исти\n",
    "    if(matchertype == \"BRUTEFORCE\"):\n",
    "        matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE)\n",
    "    elif(matchertype == \"FLANN\"):\n",
    "        matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_FLANNBASED)\n",
    "    matches = matcher.match(d1, d2, None)\n",
    "    \n",
    "    # Ги сортираме паровите поклопувања според колку се оддалечени меѓусебе,\n",
    "    # во однос на аголот, насоката и големината на дескрипторот.\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "    \n",
    "    # Ги процесираме само најдобрите X проценти\n",
    "    num_good_matches = int(len(matches) * percentageMatches)\n",
    "    good_matches = matches[:num_good_matches]\n",
    "\n",
    "    # За да се создаде хомографија од една на друга рамнина, потребни се најмалку 4 точки.\n",
    "    if(len(good_matches) < 4):\n",
    "        print(\"ERROR! Нема најмалку 4 точки за да се калкулира хомографијата!\")\n",
    "\n",
    "    # Приказ на најдените парови клучни точки кои се доволно слични, на слика\n",
    "    imMatches = cv2.drawMatches(img1, k1, img2, k2, good_matches, None, flags=2)\n",
    "    plt.xlabel(\"Најдени поклопувачки парови\", fontsize=14)\n",
    "    plt.imshow(cv2.cvtColor(imMatches, cv2.COLOR_BGRA2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    # Локациите на најдобрите парови, како низи точки\n",
    "    points1 = np.array([k1[match.queryIdx].pt for match in good_matches], dtype=np.float32)\n",
    "    points1 = points1.reshape((-1, 1, 2))\n",
    "    points2 = np.array([k2[match.trainIdx].pt for match in good_matches], dtype=np.float32)\n",
    "    points2 = points2.reshape((-1, 1, 2))\n",
    "\n",
    "    homography, mask = cv2.findHomography(points2, points1, cv2.RANSAC)\n",
    "    result2to1 = cv2.warpPerspective(img2, homography, (2*(img1.shape[1] + img2.shape[1]), (img1.shape[0] + img2.shape[0])))\n",
    "    plt.xlabel(\"Warped Слика2 според хомографијата\", fontsize=14)\n",
    "    plt.imshow(cv2.cvtColor(result2to1, cv2.COLOR_BGRA2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    # Едноставна замена на делот на новодобиената warped слика, за да ја вметнеме првата слика\n",
    "    result2to1 = addImages(img1, result2to1)\n",
    "    # result2to1[0:img1.shape[0], 0:img1.shape[1], 0:img1.shape[2]] = img1\n",
    "    plt.xlabel(\"Резултатот од сврзување на сликите\", fontsize=14)\n",
    "    plt.imshow(cv2.cvtColor(result2to1, cv2.COLOR_BGRA2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    result = result2to1\n",
    "    \n",
    "    if(crop is False):\n",
    "        # Правиме threshold за да се најдат контурите, за да може да го тргнеме новодобиениот црн дел\n",
    "        # на крајот на сликата, добиен од хомографската трансформација на втората слика.\n",
    "        gray_result = cv2.cvtColor(result, cv2.COLOR_BGRA2GRAY)\n",
    "        threshold = cv2.threshold(gray_result, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "        contours, hierarchy = cv2.findContours(threshold.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        res_contours = cv2.drawContours(result.copy(), contours, -1, (0, 255, 255))\n",
    "\n",
    "        # Приказ на контурите\n",
    "        plt.xlabel(\"Најдени контури\", fontsize=14)\n",
    "        plt.imshow(cv2.cvtColor(res_contours, cv2.COLOR_BGRA2RGB))\n",
    "        plt.show()\n",
    "\n",
    "        # Најди bounding box на контурата која има најголема плоштина, без црниот дел\n",
    "        contour_maxArea = max(contours, key=cv2.contourArea)\n",
    "        (x, y, width, height) = cv2.boundingRect(contour_maxArea)\n",
    "        result = result[y: y + height, x: x + width]\n",
    "        plt.xlabel(\"Видлива најголемата контура\", fontsize=14)\n",
    "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGRA2RGB))\n",
    "        plt.show()\n",
    "\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        # Наместо да се гледаат било какви црни региони, ги crop-нуваме само регионите од сликата кои \n",
    "        # се целосно обоени. Односно, најголемиот впишан правоаголник во целата слика. \n",
    "        # НАПОМЕНА: Овој метод брише дел од сликата кој може да биде искористен за наоѓање клучни точки\n",
    "        # со понатамошни слики, и поради тоа може да афектира на точноста на најдената хомографија.\n",
    "        \n",
    "        gray_result = cv2.cvtColor(result, cv2.COLOR_BGRA2GRAY)\n",
    "        thresh = cv2.threshold(gray_result, 1, 255, cv2.THRESH_BINARY)[1]\n",
    "        temp = thresh.copy()\n",
    "        \n",
    "        contours, _ = cv2.findContours(temp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=lambda contour:len(contour), reverse=True)\n",
    "        ROI = cv2.boundingRect(contours[0])\n",
    "\n",
    "        result = result[ROI[1]:ROI[3], ROI[0]:ROI[2]]\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cylindricalWarp(img, K):\n",
    "    \"\"\"This function returns the cylindrical warp for a given image and intrinsics matrix K\"\"\"\n",
    "    h_,w_ = img.shape[:2]\n",
    "    # pixel coordinates\n",
    "    y_i, x_i = np.indices((h_,w_))\n",
    "    X = np.stack([x_i,y_i,np.ones_like(x_i)],axis=-1).reshape(h_*w_,3) # to homog\n",
    "    Kinv = np.linalg.inv(K) \n",
    "    X = Kinv.dot(X.T).T # normalized coords\n",
    "    # calculate cylindrical coords (sin\\theta, h, cos\\theta)\n",
    "    A = np.stack([np.sin(X[:,0]),X[:,1],np.cos(X[:,0])],axis=-1).reshape(w_*h_,3)\n",
    "    B = K.dot(A.T).T # project back to image-pixels plane\n",
    "    # back from homog coords\n",
    "    B = B[:,:-1] / B[:,[-1]]\n",
    "    # make sure warp coords only within image bounds\n",
    "    B[(B[:,0] < 0) | (B[:,0] >= w_) | (B[:,1] < 0) | (B[:,1] >= h_)] = -1\n",
    "    B = B.reshape(h_,w_,-1)\n",
    "    \n",
    "    img_rgba = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA) # for transparent borders...\n",
    "    # warp the image according to cylindrical coords\n",
    "    img_rgba = cv2.remap(img_rgba, B[:,:,0].astype(np.float32), B[:,:,1].astype(np.float32), cv2.INTER_AREA, borderMode=cv2.BORDER_TRANSPARENT, borderValue=0)\n",
    "    return img_rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вчитување на листата слики и правење нова листа со самите матрици на сликите\n",
    "list_image_names = [\"images/diamondhead-05.png\", \"images/diamondhead-06.png\", \"images/diamondhead-07.png\", \"images/diamondhead-08.png\", \"images/diamondhead-09.png\", \"images/diamondhead-10.png\", \"images/diamondhead-11.png\"]\n",
    "# list_image_names = [\"images/S1.jpg\", \"images/S2.jpg\", \"images/S3.jpg\", \"images/S5.jpg\"]\n",
    "images = []\n",
    "for name in list_image_names:\n",
    "    images.append(cv2.imread(name, cv2.IMREAD_COLOR))\n",
    "\n",
    "images_copy_for_stitcher = images.copy()\n",
    "\n",
    "cylinder_images = []\n",
    "for img in images:\n",
    "    h, w = img.shape[:2]\n",
    "    K = np.array([[1800,0,w/2],[0,600,h/2],[0,0,1]])\n",
    "    cylinder_images.append(cylindricalWarp(img, K))\n",
    "\n",
    "# Параметри\n",
    "descriptorDetector = \"SIFT\" # SIFT, ORB\n",
    "matcherType = \"FLANN\" # FLANN, BRUTEFORCE\n",
    "percentageMatches = 0.3 # [0.0, 1.0]\n",
    "shouldCrop = True # True, False (НАПОМЕНА: оваа опција малку ја деградира точноста на панорамата)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ќе се процесираат сликите 2 по 2, прво сите можни парови непроцесирани слики\n",
    "# па потоа резултатите од тие процесирања, се додека немаме единствена слика во листата\n",
    "pairwise_stitches = []\n",
    "while(len(cylinder_images) > 1):\n",
    "    while(len(cylinder_images) >= 2):\n",
    "        img1 = cylinder_images[0]\n",
    "        img2 = cylinder_images[1]\n",
    "        \n",
    "        stitched = stitch(img1, img2, descriptorDetector, matcherType, percentageMatches, shouldCrop)        \n",
    "        pairwise_stitches.append(stitched)\n",
    "\n",
    "        cylinder_images.remove(img1)\n",
    "        cylinder_images.remove(img2)\n",
    "\n",
    "    if(len(cylinder_images) == 1):\n",
    "        pairwise_stitches.append(cylinder_images.pop())\n",
    "\n",
    "    cylinder_images.clear()\n",
    "    cylinder_images.extend(pairwise_stitches)\n",
    "    pairwise_stitches.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Приказ на сите слики поврзани во една панорама\n",
    "result = cylinder_images[0]\n",
    "plt.xlabel(\"Крајна панорама\", fontsize=14)\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGRA2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitcher = cv2.Stitcher_create()\n",
    "status, stitched = stitcher.stitch(images_copy_for_stitcher)\n",
    "if status == 0:\n",
    "    plt.xlabel(\"Крајна панорама од создадена од Stitcher објектот\")\n",
    "    plt.imshow(cv2.cvtColor(stitched, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
